---
title: "Homework 2"
author: "Drew Dahlquist"
date: "2/3/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1.

(a)

    $\theta$ = 16/23 = `r 16/23`. The MLE of $\theta$ is slightly greater than the posterior mean estimate under a Beta(1,1) prior which was 0.68.

(b)

    w = 2/25 = `r 2/25`. This suggests more weight from the data.

(c)

    95% CI = (`r 16/23 - 1.96*sqrt((16/23)*(7/23)/23)`, `r 16/23 + 1.96*sqrt((16/23)*(7/23)/23)`)

(d)

    Using a Beta(1,1) prior, the 95% credible interval = (`r qbeta(c(.025,.975),17,8)`).

(e)

```{r echo=FALSE}
set.seed(4640)
```

```{r 1e1, echo=FALSE}
S = 100
MC = rbeta(S,20,11)
mean0 = mean(MC)
var0 = var(MC)
cred0 = quantile(MC, c(.025,.975))
```

```{r 1e2, echo=FALSE}
S = 10000
MC = rbeta(S,20,11)
mean1 = mean(MC)
var1 = var(MC)
cred1 = quantile(MC, c(.025,.975))
```
    
    The Monte Carlo sampled estimates are often very near the analytic results we would expect. Both sample means are often correct to two decimal places, however when S=100 the sample variance and 95% credible interval tend to vary quite a lot which doesn't happen as often when S=10000.
    
|           | mean      |  variance | 95% credible interval |
| --------- | --------- | --------- | --------------------- |
| S = 100   | `r mean0` | `r var0` | (`r cred0`) |
| S = 10000 | `r mean1` | `r var1` | (`r cred1`) |
| Analytic  | `r 20/(20+11)` | `r 20*11/((20+11)^2 * (20+11+1))` | (`r qbeta(c(.025,.975),20,11)`) |

(f) The 95% HPD interval is very slightly shifted to the right on both sides when compared to the 95% central interval.

```{r 1f, echo=FALSE}
library(HDInterval)
hdi(rbeta(10000,20,11),credMass=0.95)
```

(g) $y$* = 0, 1, 2, 3, 4, 5.

(h)

```{r 1h, echo=FALSE}
library(LearnBayes)
barplot(pbetap(c(17,8),5,c(0:5)), names.arg=c(0:5), main="P[y*]",
        xlab="y*", ylab="Probability", col="orange")
```

(i)

```{r 1i, echo=FALSE}
S=10000
# Sample theta.star from it's posterior distribution
theta.star=rbeta(S,17,8)
# With n.star = 5, sample Y.star from it's posterior predictive
# distribution using theta.star
Y.star=rbinom(S,5,theta.star)
# Summarize Y.star
table(Y.star)/S
```

### 2.

(a) Gamma(188, 6.3)

    $$\\[1.5in]$$

(b)

    Yes, there is evidence of Bayesian learning. We have become much more certain about what the true value of $\lambda$ is.

```{r 2b, echo=FALSE}
lambda = seq(0,100, length=1000)

y = c(64,13,33,18,30,20)
n = length(y)
a = 10
b = 0.3

prior = dgamma(lambda, a, b)
posterior = dgamma(lambda, a+sum(y), b+n)

plot(lambda, posterior, ylab="density", type="l", col="2")
lines(lambda, prior, type="l", col="4")
legend("topright", c("Posterior", "Prior"), lty=c(1,1), col=c(2,4))
```
    
(c)

```{r 2c, echo=FALSE}
library(HDInterval)

a = a+sum(y)
b = b+n

mean = a/b
var = a/(b^2)
cred = qbeta(c(.05,.95), a, b)
hpd = hdi(rbeta(10000,a,b),credMass=0.90)
```

    Posterior mean = `r mean`, variance = `r var`, 90% central credible interval = (`r cred`), 90% HPD interval = (`r hpd`).

### 3.

```{r 3, echo=FALSE}
lambda = seq(0, 150, length=2000)
plot(lambda, dgamma(lambda, 56.25, 0.75), main="gamma(56.25, 0.75)", ylab="density", type="l", col="2")
```

\newpage

### 4.

(a) c = 1 and a = b = 0.2

```{r 4a, echo=FALSE}
library(invgamma)

c = 1
a = b = 0.2
n = 20
S = 100000

posterior.a = rinvgamma(S, a+n/2, b+15/2)

prob.a = 1-pinvgamma(c, a+n/2, b+15/2) # P[sigma^2 > c]
```

    P[$\sigma^2$> `r c`] = `r prob.a`

(b) c = 1 and a = b = 2.0

```{r 4b, echo=FALSE}
library(invgamma)

c = 1
a = b = 2.0
n = 20
S = 100000

posterior.b = rinvgamma(S, a+n/2, b+15/2)

prob.b = 1-pinvgamma(c, a+n/2, b+15/2) # P[sigma^2 > c]
```

    P[$\sigma^2$> `r c`] = `r prob.b`

(c) c = 2 and a = b = 0.2

```{r 4c, echo=FALSE}
library(invgamma)

c = 2
a = b = 0.2
n = 20
S = 100000

posterior.c = rinvgamma(S, a+n/2, b+15/2)

prob.c = 1-pinvgamma(c, a+n/2, b+15/2) # P[sigma^2 > c]
```

    P[$\sigma^2$> `r c`] = `r prob.c`

(d) c = 2 and a = b = 2.0

```{r 4d, echo=FALSE}
library(invgamma)

c = 2
a = b = 2.0
n = 20
S = 100000

posterior.d = rinvgamma(S, a+n/2, b+15/2)

prob.d = 1-pinvgamma(c, a+n/2, b+15/2) # P[sigma^2 > c]
```

    P[$\sigma^2$> `r c`] = `r prob.d`

c = 1, a = b = 0.2 / a = b = 2.0 : `r prob.a/prob.b`

c = 2, a = b = 0.2 / a = b = 2.0 : `r prob.c/prob.d`

The results for c = 2 are sensitive to the choice of prior since the ratio of probabilities between the two choices of prior is approx. 1.4. Whereas the ratio of probabilities for c = 1 is pretty close to 1.
